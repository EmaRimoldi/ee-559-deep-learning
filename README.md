# HateLens: Tiny LLMs for Efficient and Interpretable Hate Speech Detection

## Introduction

HateLens is a lightweight, transparent pipeline designed to detect and explain hate speech on social platforms. By combining the contextual power of decoder-only TinyLLMs with parameter-efficient fine-tuning and post-hoc explainability, HateLens strikes a balance between high accuracy and minimal computational overhead.

Specifically, HateLens:

- **Leverages TinyLLMs**: Fine-tunes compact, decoder-only language models via Low-Rank Adaptation (LoRA), updating less than 0.05% of parameters to keep memory footprint and inference time low.
- **Ensures Interpretability**: Integrates Local Interpretable Model-agnostic Explanations (LIME) to provide token-level attributions both before and after adaptation, making every classification decision transparent.
- **Maintains Generative Capabilities**: Preserves the base modelâ€™s generative strengths by storing only a small set of differential weights, allowing seamless reuse for other tasks.
- **Delivers State-of-the-Art Performance**: On the DynaHate benchmark, our best TinyLLM achieves over 80% accuracy; an improvement of more than 25% compared to its pre-adaptation baseline.

With HateLens, researchers and practitioners gain a fast, reliable, and explainable tool to curb the spread of hateful content without sacrificing efficiency or clarity. Perfect for deployment on edge devices, real-time moderation systems, and research environments where both performance and transparency matter.  




## ğŸ“‚ Project Structure

Below is an overview of the main folders and scripts in the repository, showing how components of the HateLens pipeline are organized:

ğŸ“¦ HateLens/  
â”œâ”€â”€ ğŸ“ **checkpoints/**  
â”‚   â”œâ”€â”€ **TinyLlama/**  
â”‚   â”‚   â”œâ”€â”€ **dynahate/**      â† 3 LoRA-tuned checkpoints (3 seeds) on DynaHate  
â”‚   â”‚   â””â”€â”€ **hatecheck/**     â† 3 LoRA-tuned checkpoints (3 seeds) on HateCheck  
â”‚   â”œâ”€â”€ **Phi-2/**  
â”‚   â”‚   â”œâ”€â”€ **dynahate/**  
â”‚   â”‚   â””â”€â”€ **hatecheck/**  
â”‚   â””â”€â”€ **OPT-1.3B/**  
â”‚       â”œâ”€â”€ **dynahate/**  
â”‚       â””â”€â”€ **hatecheck/**  
â”‚  
â”œâ”€â”€ ğŸ“ **data/**               â† Raw & preprocessed datasets  
â”‚   â”œâ”€â”€ **dynahate/**  
â”‚   â””â”€â”€ **hatecheck/**  
â”‚  
â”œâ”€â”€ ğŸ“ **experiments/**        â† YAML configs for each model  
â”‚   â”œâ”€â”€ `TinyLlama.yaml`      â† Training hyperparameters & LoRA settings  
â”‚   â”œâ”€â”€ `Phi-2.yaml`  
â”‚   â””â”€â”€ `OPT-1.3B.yaml`  
â”‚  
â”œâ”€â”€ ğŸ“ **results/**            â† Evaluation outputs & plots  
â”‚   â”œâ”€â”€ **metrics/**          â† CSVs of accuracy, F1, etc.  
â”‚   â””â”€â”€ **lime/**             â† Token-attribution scores (pre/post FT)  
â”‚  
â”œâ”€â”€ ğŸ“ **utils/**              â† Helper modules & utilities  
â”‚   â””â”€â”€ `preprocessing.py`    â† Text cleaning, tokenization scripts  
â”‚  
â”œâ”€â”€ ğŸ“„ `requirements.txt`      â† Python dependencies (LoRA, LIME, Transformersâ€¦)  
â”‚  
â”œâ”€â”€ ğŸ› ï¸ `run_training_dynahate.sh`   â† Bash wrapper to train on DynaHate  
â”œâ”€â”€ ğŸ› ï¸ `run_training_hatecheck.sh`  â† Bash wrapper to train on HateCheck  
â”‚  
â”œâ”€â”€ ğŸ‹ï¸â€â™‚ï¸ `trainer_dynahate.py`    â† PyTorch Lightning trainer for DynaHate  
â”œâ”€â”€ ğŸ‹ï¸â€â™‚ï¸ `trainer_hatecheck.py`   â† PyTorch Lightning trainer for HateCheck  
â”‚  
â”œâ”€â”€ ğŸ” `evaluate_models.py`     â†  
â”‚     â€¢ `--dynahate` â†’ evaluate best checkpoints on DynaHate  
â”‚     â€¢ `--hatecheck` â†’ evaluate best checkpoints on HateCheck  
â”‚  
â””â”€â”€ ğŸ” `compute_lime_scores.py` â†  
      â€¢ `--dynahate` â†’ compute LIME attributions on DynaHate  
      â€¢ `--hatecheck` â†’ compute LIME attributions on HateCheck  



- **checkpoints/** ğŸ“¦  
  Contains trained model weights organized by architecture and dataset. Each subfolder holds three seed-based LoRA checkpoints.

- **data/** ğŸ—„ï¸  
  Raw and preprocessed text samples for both DynaHate and HateCheck benchmarks.

- **experiments/** âš™ï¸  
  YAML configuration files capturing all hyperparameters and LoRA settings used during fine-tuning.

- **results/** ğŸ“Š  
  Evaluation metrics (accuracy, F1-score) and LIME attribution outputs, ready for plotting and analysis.

- **utils/** ğŸ› ï¸  
  Utility scripts for data preprocessing, tokenization, and other common tasks.

- **run_training_dynahate.sh** ğŸƒ  
  Shell scripts to kick off batch training jobs on dynahate dataset, selecting model via command-line flags.

- **trainer_dynahate*.py** ğŸ‹ï¸â€  
  Training pipelines leveraging PyTorch (or Lightning) to fine-tune each TinyLLM with LoRA.

- **evaluate_models.py** & **compute_lime_scores.py** ğŸ”¬  
  Python scripts to run evaluation and explainability analyses pre- and post-fine-tuning.

