# config.yaml

task_type: "SEQ_CLS"
r: 2
lora_alpha: 16
lora_dropout: 0.05
target_modules:
  - "k_proj"
  - "v_proj"

output_dir: "experiments/experiment_1/opt/checkpoints"
learning_rate: 0.001
per_device_train_batch_size: 16
per_device_eval_batch_size: 16
num_train_epochs: 3
weight_decay: 0.01
eval_strategy: "epoch"
save_strategy: "epoch"
load_best_model_at_end: true
logging_dir: "experiments/experiment_1/opt/logs/tensorboard"
logging_steps: 100
report_to: "tensorboard"
model_checkpoint: "facebook/opt-1.3b"

